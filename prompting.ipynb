{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "from blablador import Models, Completions, ChatCompletions, TokenCount\n",
    "from config import API_KEY, assistant, user, system\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "f = open('en.jsonl')\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Mistral-7B-Instruct-v0.3 - the best option in general - fast and good (If it fails to respond then choose another model)\n",
      "10 Mistral-Nemo-Instruct-2407 - New Mistral Nemo - give it a try\n",
      "2 - Mixtral-8x7B-Instruct-v0.1 Slower with higher quality\n",
      "3 - starcoder2-15b - A model for programming\n",
      "4 - Cosmosage V3.1 - Answers your Cosmology and Astronomy questions (new version September 2024)\n",
      "5 - GritLM-7B - For Chat AND Text Embeddings\n",
      "6 - Llama3.1-8B-Instruct - A good model from META (update July 2024)\n",
      "alias-code\n",
      "alias-cosmosage\n",
      "alias-embeddings\n",
      "alias-fast\n",
      "alias-fast-experimental\n",
      "alias-large\n",
      "alias-llama3-small\n",
      "gpt-3.5-turbo\n",
      "text-davinci-003\n",
      "text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Retrieve available models\n",
    "models = Models(api_key=API_KEY).get_model_ids()\n",
    "for i in models:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with promting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_for_testing = \"A car initially at rest accelerates in a straight line at 3 m/s\\u00b2. What will be its speed after 2 seconds? Give just the number of correct answer without explanationsA: 0 m/s, B: 5 m/s, C: 3 m/s, D: 6 m/s, E: 2 m/s\"\n",
    "text_for_prompt = \"Your task is to provide a direct answer to my question, selecting from four options.Please give only the letter corresponding to the correct answer without any explanations or additional information.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Full-reply, no promts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '## Step 1: Recall the formula for calculating speed under constant acceleration.\\nThe formula to calculate the final speed (v) of an object under constant acceleration (a) is given by v = u + at, where u is the initial speed, a is the acceleration, and t is the time.\\n\\n## Step 2: Identify the given values.\\nThe initial speed (u) of the car is 0 m/s since it is initially at rest, the acceleration (a) is 3'}\n"
     ]
    }
   ],
   "source": [
    "# Generate chat completions\n",
    "completion = ChatCompletions(api_key=API_KEY, model=models[6])\n",
    "response = completion.get_completion([{\"role\":\"user\", \"content\":q_for_testing}])\n",
    "# Returns a JSON string\n",
    "#print(ast.literal_eval(response)['model'])\n",
    "print(ast.literal_eval(response)[\"choices\"][0][\"message\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role: user, Promt: .., Content: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'D'}\n"
     ]
    }
   ],
   "source": [
    "# Generate chat completions\n",
    "completion = ChatCompletions(api_key=API_KEY, model=models[6])\n",
    "response = completion.get_completion([{\"role\":\"user\", \"promt\":text_for_prompt ,\"content\":q_for_testing},])\n",
    "# Returns a JSON string\n",
    "\n",
    "print(ast.literal_eval(response)[\"choices\"][0][\"message\"])\n",
    "#{'role': 'assistant', 'content': \"I'm not capable of experiencing emotions or having a physical body, but...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promt in the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'D'}\n"
     ]
    }
   ],
   "source": [
    "# Generate chat completions\n",
    "completion = ChatCompletions(api_key=API_KEY, model=models[6])\n",
    "response = completion.get_completion([{\"role\":\"user\",\"content\":q_for_testing + text_for_prompt}])\n",
    "# Returns a JSON string\n",
    "\n",
    "print(ast.literal_eval(response)[\"choices\"][0][\"message\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using role: system message. No examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'D'}\n"
     ]
    }
   ],
   "source": [
    "# Generate chat completions\n",
    "completion = ChatCompletions(api_key=API_KEY, model=models[6])\n",
    "response = completion.get_completion([{\"role\":\"system\", \"content\": text_for_prompt},\n",
    "                                      {\"role\":\"user\", \"content\":q_for_testing}\n",
    "                                      ])\n",
    "# Returns a JSON string\n",
    "\n",
    "print(ast.literal_eval(response)[\"choices\"][0][\"message\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot promting. User-assistant messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'D'}\n"
     ]
    }
   ],
   "source": [
    "completion = ChatCompletions(api_key=API_KEY, model=models[6])\n",
    "response = completion.get_completion(messages=[\n",
    "    user(\"You’re a highly knowledgeable physics tutor. For each message, give only the letter of the correct answer without any explanations or additional information.\"),\n",
    "    user(\"A ball rolls down a slope and accelerates uniformly at 2 m/s². If it starts from rest, what will be its speed after 3 seconds? A. 3 m/s, B. 4 m/s, C. 5 m/s, D. 6 m/s, E. 7 m/s\"),\n",
    "    assistant(\"D\"),\n",
    "    user(\"A cyclist accelerates uniformly from rest to a speed of 10 m/s in 5 seconds. What is their acceleration? A. 1 m/s², B. 2 m/s², C. 3 m/s², D. 4 m/s², E. 5 m/s²r\"),\n",
    "    assistant(\"B\"),\n",
    "    user(\"A rocket accelerates from rest at a constant rate of 6 m/s². What speed will it reach after 4 seconds? A. 12 m/s, B. 18 m/s, C. 24 m/s, D. 30 m/s, E. 36 m/s\"),\n",
    "    assistant(\"C\"),\n",
    "    user(q_for_testing),\n",
    "    ])\n",
    "print(ast.literal_eval(response)[\"choices\"][0][\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model with promts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: 6 - Llama3.1-8B-Instruct - A good model from META (update July 2024)\n"
     ]
    }
   ],
   "source": [
    "ground_truth_llama, responses_llama = run_model_promting(path_to_questions = 'en.jsonl', path_to_answers = 'responses/responses_test.txt', model_id = 6,start_range = 0, end_range = 3, N_samples = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_unc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
